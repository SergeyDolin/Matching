{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7043822,"sourceType":"datasetVersion","datasetId":4052970}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Мэтчинг товаров","metadata":{}},{"cell_type":"markdown","source":"Цель проекта: Подобрать и обучить модель на исходных данных, способную найти 5 похожих товаров для валиадационной выборки из датасета base, основываясь на метрики accuracy@5.\n\nЗадачи:\n- Загрузка датасетов и предварительный обзор;\n- EDA;\n- Построение Baseline-моделей и выбор наилучшего варианта;\n- Предобработка данных перед обучением;\n- Обучение модели и анализ результатов\n\nИнтерументы: В проекте использовались алгоритмы реализованные в библиотеки FAISS, обучение происходило на GPU.","metadata":{}},{"cell_type":"code","source":"# %conda install -c pytorch faiss-cpu (если нет CUDA)\n%conda install -c conda-forge faiss-gpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%conda install -c \"conda-forge/label/broken\" faiss-gpu","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Импорты и константы","metadata":{}},{"cell_type":"markdown","source":"### Импорты","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport faiss\nimport sweetviz as sv\nimport numpy as np\nfrom sklearn.preprocessing import RobustScaler\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Константы","metadata":{}},{"cell_type":"code","source":"k_similar = 5 # Количество (соседей) похожих товаров","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка и обзор данных","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('./Data/train.csv', index_col=0) \nvalid = pd.read_csv('./Data/validation.csv', index_col=0)\nvalid_awr = pd.read_csv('./Data/validation_answer.csv', index_col=0)\nbase = pd.read_csv('./Data/base.csv', index_col=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe().T\\\n    .style.bar(subset=['mean'], color=px.colors.qualitative.G10[2])\\\n    .background_gradient(subset=['std'], cmap='Blues')\\\n    .background_gradient(subset=['50%'], cmap='BuGn')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base.describe().T\\\n    .style.bar(subset=['mean'], color=px.colors.qualitative.G10[2])\\\n    .background_gradient(subset=['std'], cmap='Blues')\\\n    .background_gradient(subset=['50%'], cmap='BuGn')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Сразу можно обратить внимание, что есть некоторые признаки, которые имеют сильный разброс по стандартному отклонению, этот фактор может являтся ключевым при обучении модели.\n\nДатасет: Набор даннх имеет 72 признака, в Base имеется порядка 3 млн. записей, пропуски и дубликаты в данных отсутсвуют. Данные представленны ввиде вещественных чисел Float64.","metadata":{}},{"cell_type":"code","source":"d = base.shape[1] # Получим количество признаков\nd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_t = train.drop('Target', axis=1) # Из датасета Train возьмем признаки","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Выполним явное преобразование типов данных в датасетах, для уменьшения занимаемого пространства","metadata":{}},{"cell_type":"code","source":"features_t = features_t.astype('float32')\nvalid = valid.astype('float32')\nbase = base.astype('float32')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ngpu = 2 # Количество видеокарт","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"markdown","source":"Воспользуемся библиотекой `sweetviz` для быстрого анализа данных","metadata":{}},{"cell_type":"code","source":"train_report = sv.analyze(base)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_report.show_html('Base_report.html')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Baseline (FAISS)","metadata":{}},{"cell_type":"markdown","source":"Для решения задачи метчинага была выбрана одна из наиболее эффективных и популярных библитек от Facebook - FAISS. \n\nВ работе исследованы модели `FlatL2` `IVF` `HNSW`.","metadata":{}},{"cell_type":"markdown","source":"### Flat L2","metadata":{}},{"cell_type":"code","source":"index = faiss.IndexFlatL2(d)\nresources = [faiss.StandardGpuResources() for i in range(ngpu)]\nindex_gpu = faiss.index_cpu_to_gpu_multiple_py(resources, index)\nindex_gpu.add(base)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_index = {k: v for k, v in enumerate(base.index.to_list())}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = train[\"Target\"]","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets_v = valid_awr['Expected']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(features_t, k_similar)\nacc = 0\nfor target, el in zip(targets.values.tolist(), I.tolist()):\n    acc += int(target in [base_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(valid, k_similar)\nacc = 0\nfor target, el in zip(targets_v.values.tolist(), I.tolist()):\n    acc += int(target in [base_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## IVF","metadata":{}},{"cell_type":"code","source":"nlist = 18\n\nquant = faiss.IndexFlatIP(d)\nindex = faiss.IndexIVFFlat(quant, d, nlist)\n\nresources = [faiss.StandardGpuResources() for i in range(ngpu)]\nindex_gpu = faiss.index_cpu_to_gpu_multiple_py(resources, index)\n\nindex_gpu.train(base)\nindex_gpu.add(base)\nindex_gpu.nprobe = 8","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(features_t, k_similar)\nacc = 0\nfor target, el in zip(targets.values.tolist(), I.tolist()):\n    acc += int(target in [base_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(valid, k_similar)\nacc = 0\nfor target, el in zip(targets_v.values.tolist(), I.tolist()):\n    acc += int(target in [base_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## HNSW","metadata":{}},{"cell_type":"code","source":"index = faiss.IndexHNSWFlat(d, 1024)\nresources = [faiss.StandardGpuResources() for i in range(ngpu)]\nindex_gpu = faiss.index_cpu_to_gpu_multiple_py(resources, index)\nindex_gpu.add(base)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(features_t, k_similar)\nacc = 0\nfor target, el in zip(targets.values.tolist(), I.tolist()):\n    acc += int(target in [base_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(valid, k_similar)\nacc = 0\nfor target, el in zip(targets_v.values.tolist(), I.tolist()):\n    acc += int(target in [base_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Результаты baseline","metadata":{}},{"cell_type":"markdown","source":"**Выбор модели**\n\nБыли рассмотрены три модели `FlatL2` `IVF` и `HNSW`. Для опеределения наилучшей модели была использована метрика accuracy@5 (среднее значение accuracy для 5 метчей).\n\n\n**Обучение моделей**\n\nПоказатели метрик для валидационной выборки:\n- `FlatL2`\n    - Accuracy@5 `13.286`\n- `IVF`\n    - Accuracy@5 `13.155`\n- `HNSW`\n    - Accuracy@5 `11.431`\n\nДалее будет использоваться модель **FlatL2**","metadata":{}},{"cell_type":"markdown","source":"## Предобработка данных","metadata":{}},{"cell_type":"markdown","source":"Проверим данные на нормальность (подчинению закону нормального расспределения); Проведем тест Шапиро-Уилка; Оценим параметр ассиметрии данных (skew); Выполним масштабирование данных.","metadata":{}},{"cell_type":"code","source":"base.hist(figsize=[20, 20], bins=50);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Тест Шапиро-Улка на нормальность данных","metadata":{}},{"cell_type":"markdown","source":"Отметим только те признаки которые попадают в интервал 3-х sigm, на небольшом отрезке данных (При величине вектора больше 5000, p-value будет работать нестабильно) ","metadata":{}},{"cell_type":"code","source":"from scipy.stats import shapiro \n\ndef statistic(x):\n    return shapiro(x).statistic\n\nfor i in base:\n    if statistic(base[i][:5000]) <= 0.99:\n        print(i, statistic(base[i][:5000]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SKEW","metadata":{}},{"cell_type":"code","source":"def summary(df):\n    sum = pd.DataFrame(df.dtypes, columns=['dtypes'])\n    sum['count'] = df.count().values\n    sum['skew'] = df.skew().values\n    return sum\n\ns = summary(base)\ns.style.background_gradient(cmap='Blues')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s.query('skew > 0.5 or skew < -0.5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Уберем из наших исходных данных признаки которые не подчиняются закону нормального расспределения","metadata":{}},{"cell_type":"code","source":"base_norm = base.drop(['6','21','25','33','44','59','63','65','70'], axis=1)\ntrain_norm = train.drop(['6','21','25','33','44','59','63','65','70'], axis=1)\nvalid_norm = valid.drop(['6','21','25','33','44','59','63','65','70'], axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_t_norm = train_norm.drop('Target', axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Мультиколлениарность","metadata":{}},{"cell_type":"markdown","source":"Выполним проверку на мультиколлениарность данных","metadata":{}},{"cell_type":"code","source":"vif_data = pd.DataFrame()\nvif_data[\"feature\"] = base_norm.columns\n\n# вычисление VIF для каждого признака\nvif_data[\"VIF\"] = [variance_inflation_factor(base_norm.values, i)\n                          for i in range(len(base_norm.columns))]\n  \nprint(vif_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VIF_features_drop = vif_data.query('VIF > 9.0')['feature']\nVIF_features_drop","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_vif = base_norm.drop(VIF_features_drop.values, axis=1)\ntrain_vif = train_norm.drop(VIF_features_drop.values, axis=1)\nvalid_vif = valid_norm.drop(VIF_features_drop.values, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features_t_vif = train_vif.drop('Target', axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_vif.hist(figsize=[20, 20], bins=50);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Масштабирование ","metadata":{}},{"cell_type":"code","source":"scaler = RobustScaler()\nbase_slr_vif = scaler.fit_transform(base_vif)\nfeatures_slr_vif = scaler.transform(features_t_vif)\nvalid_slr_vif = scaler.transform(valid_vif)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение модели","metadata":{}},{"cell_type":"code","source":"d_vif = base_slr_vif.shape[1]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index = faiss.IndexFlatL2(d_vif)\nindex.add(base_slr_vif)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resources = [faiss.StandardGpuResources() for i in range(ngpu)]\nindex_gpu = faiss.index_cpu_to_gpu_multiple_py(resources, index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_vif_index = {k: v for k, v in enumerate(base_vif.index.to_list())}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(features_slr_vif, k_similar)\nacc = 0\nfor target, el in zip(target_vif.values.tolist(), I.tolist()):\n    acc += int(target in [base_vif_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nD, I = index_gpu.search(valid_slr_vif, k_similar)\nacc = 0\nfor target, el in zip(targets_v.values.tolist(), I.tolist()):\n    acc += int(target in [base_vif_index[r] for r in el])\n\nprint(100 * acc / len(I))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Выводы","metadata":{}},{"cell_type":"markdown","source":"Цель проекта было подобрать и обучить модель на исходных данных, способную найти 5 похожих товаров для валиадационной выборки из датасета base, основываясь на метрики accuracy@5.\n\nВыполненые задачи:\n- Загрузка датасетов и предварительный обзор;\n- EDA;\n- Построение Baseline-моделей и выбор наилучшего варианта;\n- Предобработка данных перед обучением;\n- Обучение модели и анализ результатов\n\nДля решения задачи метчинага была выбрана одна из наиболее эффективных и популярных библитек от Facebook - FAISS. \n\nВ работе исследованы модели `FlatL2` `IVF` и `HNSW`.\n\nПоказатели метрик для валидационной выборки:\n- `FlatL2`\n    - Accuracy@5 `13.286`\n- `IVF`\n    - Accuracy@5 `13.155`\n- `HNSW`\n    - Accuracy@5 `11.431`\n\nДалее использовалась модель **FlatL2**\n\nИтоговые результаты для валидационной выборки:\n- `FlatL2`\n    - Accuracy@5 `69.569`","metadata":{}}]}